{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"interpreter":{"hash":"452664ae0eb597dd3a1b83725f0d9ce2a5dbc90def01fdcd30762fd3552c6140"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8822451,"sourceType":"datasetVersion","datasetId":5307616}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"We are using PyTorch as our deep learning framework. \nImporting necessary libraries to pre-processing, tokenizing, train, writing model states and evaluation.","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, RandomSampler, SequentialSampler\nfrom torch.utils.data import TensorDataset\n\nfrom tqdm.notebook import tqdm\nfrom tqdm.auto import tqdm\n\nfrom transformers import BertTokenizer\nfrom transformers import BertForSequenceClassification\nfrom transformers import AdamW, get_linear_schedule_with_warmup","metadata":{"execution":{"iopub.status.busy":"2024-06-30T16:30:16.495234Z","iopub.execute_input":"2024-06-30T16:30:16.495585Z","iopub.status.idle":"2024-06-30T16:30:21.736132Z","shell.execute_reply.started":"2024-06-30T16:30:16.495558Z","shell.execute_reply":"2024-06-30T16:30:21.735331Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport gensim\nimport zipfile\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\n\nimport random\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T16:30:21.738015Z","iopub.execute_input":"2024-06-30T16:30:21.738487Z","iopub.status.idle":"2024-06-30T16:30:35.048246Z","shell.execute_reply.started":"2024-06-30T16:30:21.738442Z","shell.execute_reply":"2024-06-30T16:30:35.047279Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"Checking the device. We will proceed if there is a GPU available.","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nprint(torch.cuda.device_count())\nif device.type == 'cuda':\n    print(torch.cuda.get_device_name(0))\n    print('Memory Usage:')\n    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\nelse:\n    exit(0)\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-06-30T16:30:35.049545Z","iopub.execute_input":"2024-06-30T16:30:35.050162Z","iopub.status.idle":"2024-06-30T16:30:35.134941Z","shell.execute_reply.started":"2024-06-30T16:30:35.050127Z","shell.execute_reply":"2024-06-30T16:30:35.134131Z"},"trusted":true},"outputs":[{"name":"stdout","text":"2\nTesla T4\nMemory Usage:\nAllocated: 0.0 GB\nCached:    0.0 GB\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"Download the train set and load into a DataFrame","metadata":{}},{"cell_type":"code","source":"#if not os.path.exists(\"./Dataset\"):\n#    os.makedirs(\"./Dataset\")\n\n#if not os.path.isfile(\"./Dataset/github-labels-top3-803k-train.csv\"):\n#    !curl \"https://tickettagger.blob.core.windows.net/datasets/github-labels-top3-803k-train.tar.gz\" | tar -xz \n#    !mv github-labels-top3-803k-train.csv ./Dataset/\n\ndataset_path = '/kaggle/input/tweet-classification-dataset/Corona_NLP_train.csv'\n\ndf = pd.read_csv(dataset_path, encoding='latin-1')\n\nprint(df.head())\n\n#df = pd.read_csv('/kaggle/input/tweet-classification-dataset')\n#print(df.head())","metadata":{"execution":{"iopub.status.busy":"2024-06-30T16:30:35.137609Z","iopub.execute_input":"2024-06-30T16:30:35.138172Z","iopub.status.idle":"2024-06-30T16:30:35.428833Z","shell.execute_reply.started":"2024-06-30T16:30:35.138144Z","shell.execute_reply":"2024-06-30T16:30:35.427821Z"},"trusted":true},"outputs":[{"name":"stdout","text":"   UserName  ScreenName   Location     TweetAt  \\\n0      3799       48751     London  16-03-2020   \n1      3800       48752         UK  16-03-2020   \n2      3801       48753  Vagabonds  16-03-2020   \n3      3802       48754        NaN  16-03-2020   \n4      3803       48755        NaN  16-03-2020   \n\n                                       OriginalTweet           Sentiment  \n0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n1  advice Talk to your neighbours family to excha...            Positive  \n2  Coronavirus Australia: Woolworths to give elde...            Positive  \n3  My food stock is not the only one which is emp...            Positive  \n4  Me, ready to go at supermarket during the #COV...  Extremely Negative  \n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"Check the labels and map to a index value. ","metadata":{}},{"cell_type":"code","source":"print(df['Sentiment'].value_counts())\npossible_labels = df.Sentiment.unique()\n\nlabel_dict = {}\nfor index, possible_label in enumerate(possible_labels):\n    label_dict[possible_label] = index\nprint(label_dict)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T16:30:35.430008Z","iopub.execute_input":"2024-06-30T16:30:35.430373Z","iopub.status.idle":"2024-06-30T16:30:35.452819Z","shell.execute_reply.started":"2024-06-30T16:30:35.430345Z","shell.execute_reply":"2024-06-30T16:30:35.451695Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Sentiment\nPositive              11422\nNegative               9917\nNeutral                7713\nExtremely Positive     6624\nExtremely Negative     5481\nName: count, dtype: int64\n{'Neutral': 0, 'Positive': 1, 'Extremely Negative': 2, 'Negative': 3, 'Extremely Positive': 4}\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"Replace the label colomn with label index.","metadata":{}},{"cell_type":"code","source":"df['label'] = df.Sentiment.replace(label_dict)\n\nprint(df.head())","metadata":{"execution":{"iopub.status.busy":"2024-06-30T16:30:35.453991Z","iopub.execute_input":"2024-06-30T16:30:35.454256Z","iopub.status.idle":"2024-06-30T16:30:35.497743Z","shell.execute_reply.started":"2024-06-30T16:30:35.454234Z","shell.execute_reply":"2024-06-30T16:30:35.496852Z"},"trusted":true},"outputs":[{"name":"stdout","text":"   UserName  ScreenName   Location     TweetAt  \\\n0      3799       48751     London  16-03-2020   \n1      3800       48752         UK  16-03-2020   \n2      3801       48753  Vagabonds  16-03-2020   \n3      3802       48754        NaN  16-03-2020   \n4      3803       48755        NaN  16-03-2020   \n\n                                       OriginalTweet           Sentiment  \\\n0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral   \n1  advice Talk to your neighbours family to excha...            Positive   \n2  Coronavirus Australia: Woolworths to give elde...            Positive   \n3  My food stock is not the only one which is emp...            Positive   \n4  Me, ready to go at supermarket during the #COV...  Extremely Negative   \n\n   label  \n0      0  \n1      1  \n2      1  \n3      1  \n4      2  \n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_34/2408131205.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  df['label'] = df.Sentiment.replace(label_dict)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"Pre-preocessing function for removing whitespace and creating new feature.","metadata":{}},{"cell_type":"code","source":"# preprocessing can be customized by participants\ndef preprocess(row):\n  # concatenate title and body, then remove whitespaces\n  doc = \"\"\n  doc += str(row.TweetAt)\n  doc += \" \"\n  doc += str(row.OriginalTweet)\n  # https://radimrehurek.com/gensim/parsing/preprocessing.html\n  doc = gensim.parsing.preprocessing.strip_multiple_whitespaces(doc)\n  return doc","metadata":{"execution":{"iopub.status.busy":"2024-06-30T16:30:35.499040Z","iopub.execute_input":"2024-06-30T16:30:35.499709Z","iopub.status.idle":"2024-06-30T16:30:35.504943Z","shell.execute_reply.started":"2024-06-30T16:30:35.499677Z","shell.execute_reply":"2024-06-30T16:30:35.503947Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"Applying preporcessing step on the dataframe.","metadata":{}},{"cell_type":"code","source":"df['tweet_info'] = df.apply(preprocess, axis=1)\nprint(df.head())\n\nnewDF = df[['Sentiment','OriginalTweet','label']]\ndf = newDF.copy()\nprint(df.head())","metadata":{"execution":{"iopub.status.busy":"2024-06-30T16:30:35.506259Z","iopub.execute_input":"2024-06-30T16:30:35.506500Z","iopub.status.idle":"2024-06-30T16:30:38.203346Z","shell.execute_reply.started":"2024-06-30T16:30:35.506479Z","shell.execute_reply":"2024-06-30T16:30:38.202461Z"},"trusted":true},"outputs":[{"name":"stdout","text":"   UserName  ScreenName   Location     TweetAt  \\\n0      3799       48751     London  16-03-2020   \n1      3800       48752         UK  16-03-2020   \n2      3801       48753  Vagabonds  16-03-2020   \n3      3802       48754        NaN  16-03-2020   \n4      3803       48755        NaN  16-03-2020   \n\n                                       OriginalTweet           Sentiment  \\\n0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral   \n1  advice Talk to your neighbours family to excha...            Positive   \n2  Coronavirus Australia: Woolworths to give elde...            Positive   \n3  My food stock is not the only one which is emp...            Positive   \n4  Me, ready to go at supermarket during the #COV...  Extremely Negative   \n\n   label                                         tweet_info  \n0      0  16-03-2020 @MeNyrbie @Phil_Gahan @Chrisitv htt...  \n1      1  16-03-2020 advice Talk to your neighbours fami...  \n2      1  16-03-2020 Coronavirus Australia: Woolworths t...  \n3      1  16-03-2020 My food stock is not the only one w...  \n4      2  16-03-2020 Me, ready to go at supermarket duri...  \n            Sentiment                                      OriginalTweet  \\\n0             Neutral  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...   \n1            Positive  advice Talk to your neighbours family to excha...   \n2            Positive  Coronavirus Australia: Woolworths to give elde...   \n3            Positive  My food stock is not the only one which is emp...   \n4  Extremely Negative  Me, ready to go at supermarket during the #COV...   \n\n   label  \n0      0  \n1      1  \n2      1  \n3      1  \n4      2  \n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"Split the dataset into train and validation set.","metadata":{}},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(df.index.values, \n                                                  df.label.values, \n                                                  test_size=0.15, \n                                                  random_state=42, \n                                                  stratify=df.label.values)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T16:30:38.204383Z","iopub.execute_input":"2024-06-30T16:30:38.204669Z","iopub.status.idle":"2024-06-30T16:30:38.229296Z","shell.execute_reply.started":"2024-06-30T16:30:38.204644Z","shell.execute_reply":"2024-06-30T16:30:38.228385Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"Marking train and validation data.","metadata":{}},{"cell_type":"code","source":"df['data_type'] = ['not_set']*df.shape[0]\n\nprint(df.head())\ndf.loc[X_train, 'data_type'] = 'train'\ndf.loc[X_val, 'data_type'] = 'val'\n\nprint(df.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T16:30:38.232221Z","iopub.execute_input":"2024-06-30T16:30:38.232509Z","iopub.status.idle":"2024-06-30T16:30:38.250620Z","shell.execute_reply.started":"2024-06-30T16:30:38.232484Z","shell.execute_reply":"2024-06-30T16:30:38.249786Z"},"trusted":true},"outputs":[{"name":"stdout","text":"            Sentiment                                      OriginalTweet  \\\n0             Neutral  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...   \n1            Positive  advice Talk to your neighbours family to excha...   \n2            Positive  Coronavirus Australia: Woolworths to give elde...   \n3            Positive  My food stock is not the only one which is emp...   \n4  Extremely Negative  Me, ready to go at supermarket during the #COV...   \n\n   label data_type  \n0      0   not_set  \n1      1   not_set  \n2      1   not_set  \n3      1   not_set  \n4      2   not_set  \n            Sentiment                                      OriginalTweet  \\\n0             Neutral  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...   \n1            Positive  advice Talk to your neighbours family to excha...   \n2            Positive  Coronavirus Australia: Woolworths to give elde...   \n3            Positive  My food stock is not the only one which is emp...   \n4  Extremely Negative  Me, ready to go at supermarket during the #COV...   \n\n   label data_type  \n0      0     train  \n1      1     train  \n2      1     train  \n3      1     train  \n4      2     train  \n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"Initiating BertTokenizer from 'bert-base-uncased' model.","metadata":{}},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T16:30:38.251690Z","iopub.execute_input":"2024-06-30T16:30:38.251985Z","iopub.status.idle":"2024-06-30T16:30:39.014257Z","shell.execute_reply.started":"2024-06-30T16:30:38.251959Z","shell.execute_reply":"2024-06-30T16:30:39.013377Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65f8cda617664b7eb459fa84ccea727d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57c587be65f54fee994e647ea59e6553"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86bdad159df941e197d511752b4057f5"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69f8d4367b144801b162e96077543764"}},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"Encoding train set.","metadata":{}},{"cell_type":"code","source":"encoded_data_train = tokenizer.batch_encode_plus(\n    df[df.data_type=='train'].OriginalTweet.values, \n    add_special_tokens=True, \n    return_attention_mask=True, \n    padding='longest',\n    truncation=True, \n    return_tensors='pt'\n)\n\ninput_ids_train = encoded_data_train['input_ids']\nattention_masks_train = encoded_data_train['attention_mask']\nlabels_train = torch.tensor(df[df.data_type=='train'].label.values)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T16:30:39.015528Z","iopub.execute_input":"2024-06-30T16:30:39.015832Z","iopub.status.idle":"2024-06-30T16:31:38.094280Z","shell.execute_reply.started":"2024-06-30T16:30:39.015806Z","shell.execute_reply":"2024-06-30T16:31:38.093423Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"Encoding validation set.","metadata":{}},{"cell_type":"code","source":"encoded_data_val = tokenizer.batch_encode_plus(\n    df[df.data_type=='val'].OriginalTweet.values, \n    add_special_tokens=True, \n    return_attention_mask=True, \n    padding='longest',\n    truncation=True,\n    return_tensors='pt'\n)\n\ninput_ids_val = encoded_data_val['input_ids']\nattention_masks_val = encoded_data_val['attention_mask']\nlabels_val = torch.tensor(df[df.data_type=='val'].label.values)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T16:31:38.095762Z","iopub.execute_input":"2024-06-30T16:31:38.096040Z","iopub.status.idle":"2024-06-30T16:31:47.876419Z","shell.execute_reply.started":"2024-06-30T16:31:38.096015Z","shell.execute_reply":"2024-06-30T16:31:47.875427Z"},"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"Creating TensorDataset from encoded and masked train and validation set.","metadata":{}},{"cell_type":"code","source":"dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\ndataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\nprint(len(dataset_train), len(dataset_val))\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T16:31:47.877649Z","iopub.execute_input":"2024-06-30T16:31:47.878025Z","iopub.status.idle":"2024-06-30T16:31:47.885208Z","shell.execute_reply.started":"2024-06-30T16:31:47.877992Z","shell.execute_reply":"2024-06-30T16:31:47.884131Z"},"trusted":true},"outputs":[{"name":"stdout","text":"34983 6174\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"Initiating model from 'bert-base-uncased' pretrained model.","metadata":{}},{"cell_type":"code","source":"model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n                                                      num_labels=len(label_dict),\n                                                      output_attentions=False,\n                                                      output_hidden_states=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T16:31:47.886121Z","iopub.execute_input":"2024-06-30T16:31:47.886382Z","iopub.status.idle":"2024-06-30T16:31:50.706649Z","shell.execute_reply.started":"2024-06-30T16:31:47.886359Z","shell.execute_reply":"2024-06-30T16:31:50.705907Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec639380a7a34aa48f1131f3a3142a0e"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"Fixing batch_size and creating dataloader for training and validating.","metadata":{}},{"cell_type":"code","source":"\nbatch_size = 4\n\ndataloader_train = DataLoader(dataset_train, \n                              sampler=RandomSampler(dataset_train), \n                              batch_size=batch_size)\n\ndataloader_validation = DataLoader(dataset_val, \n                                   sampler=SequentialSampler(dataset_val), \n                                   batch_size=batch_size)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T16:31:50.707733Z","iopub.execute_input":"2024-06-30T16:31:50.707979Z","iopub.status.idle":"2024-06-30T16:31:50.715426Z","shell.execute_reply.started":"2024-06-30T16:31:50.707957Z","shell.execute_reply":"2024-06-30T16:31:50.714463Z"},"trusted":true},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"Initiating optimizer.","metadata":{}},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(),\n                  lr=1e-5, \n                  eps=1e-8)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T16:31:50.716522Z","iopub.execute_input":"2024-06-30T16:31:50.717310Z","iopub.status.idle":"2024-06-30T16:31:50.728012Z","shell.execute_reply.started":"2024-06-30T16:31:50.717277Z","shell.execute_reply":"2024-06-30T16:31:50.727139Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"Fixing epochs number and initiating scheduler.","metadata":{}},{"cell_type":"code","source":"epochs = 4\n\nscheduler = get_linear_schedule_with_warmup(optimizer, \n                                            num_warmup_steps=0,\n                                            num_training_steps=len(dataloader_train)*epochs)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T16:31:50.728936Z","iopub.execute_input":"2024-06-30T16:31:50.729231Z","iopub.status.idle":"2024-06-30T16:31:50.733945Z","shell.execute_reply.started":"2024-06-30T16:31:50.729207Z","shell.execute_reply":"2024-06-30T16:31:50.733010Z"},"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"Declaring functions for evaluting.","metadata":{}},{"cell_type":"code","source":"def f1_score_func(preds, labels):\n    preds_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return f1_score(labels_flat, preds_flat, average='weighted')\n    \ndef evaluate(dataloader_val):\n\n    model.eval()\n    \n    loss_val_total = 0\n    predictions, true_vals = [], []\n    \n    for batch in dataloader_val:\n        \n        batch = tuple(b.to(device) for b in batch)\n        \n        inputs = {'input_ids':      batch[0],\n                  'attention_mask': batch[1],\n                  'labels':         batch[2],\n                 }\n\n        with torch.no_grad():        \n            outputs = model(**inputs)\n            \n        loss = outputs[0]\n        logits = outputs[1]\n        loss_val_total += loss.item()\n\n        logits = logits.detach().cpu().numpy()\n        label_ids = inputs['labels'].cpu().numpy()\n        predictions.append(logits)\n        true_vals.append(label_ids)\n    \n    loss_val_avg = loss_val_total/len(dataloader_val) \n    \n    predictions = np.concatenate(predictions, axis=0)\n    true_vals = np.concatenate(true_vals, axis=0)\n            \n    return loss_val_avg, predictions, true_vals","metadata":{"execution":{"iopub.status.busy":"2024-06-30T16:31:50.735049Z","iopub.execute_input":"2024-06-30T16:31:50.735354Z","iopub.status.idle":"2024-06-30T16:31:50.745226Z","shell.execute_reply.started":"2024-06-30T16:31:50.735331Z","shell.execute_reply":"2024-06-30T16:31:50.744147Z"},"trusted":true},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"Fixing seed value for random sampling.","metadata":{}},{"cell_type":"code","source":"\nseed_val = 17\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T16:31:50.746245Z","iopub.execute_input":"2024-06-30T16:31:50.746518Z","iopub.status.idle":"2024-06-30T16:31:50.755981Z","shell.execute_reply.started":"2024-06-30T16:31:50.746495Z","shell.execute_reply":"2024-06-30T16:31:50.755271Z"},"trusted":true},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"Moving the model to GPU.","metadata":{}},{"cell_type":"code","source":"model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T16:31:50.756907Z","iopub.execute_input":"2024-06-30T16:31:50.757195Z","iopub.status.idle":"2024-06-30T16:31:51.026786Z","shell.execute_reply.started":"2024-06-30T16:31:50.757171Z","shell.execute_reply":"2024-06-30T16:31:51.025852Z"},"trusted":true},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=5, bias=True)\n)"},"metadata":{}}],"execution_count":21},{"cell_type":"markdown","source":"Starting the training process.","metadata":{}},{"cell_type":"code","source":"for epoch in tqdm(range(1, epochs+1)):\n    \n    model.train()\n    \n    loss_train_total = 0\n\n    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n    for batch in progress_bar:\n\n        model.zero_grad()\n        \n        batch = tuple(b.to(device) for b in batch)\n        \n        inputs = {'input_ids':      batch[0],\n                  'attention_mask': batch[1],\n                  'labels':         batch[2],\n                 }       \n\n        outputs = model(**inputs)\n        \n        loss = outputs[0]\n        loss_train_total += loss.item()\n        loss.backward()\n\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n        optimizer.step()\n        scheduler.step()\n        \n        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n         \n        \n    torch.save(model.state_dict(), f'/kaggle/working/model.pth')   \n    tqdm.write(f'\\nEpoch {epoch}')\n    \n    loss_train_avg = loss_train_total/len(dataloader_train)            \n    tqdm.write(f'Training loss: {loss_train_avg}')\n    \n    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n    val_f1 = f1_score_func(predictions, true_vals)\n    tqdm.write(f'Validation loss: {val_loss}')\n    tqdm.write(f'F1 Score (Weighted): {val_f1}')","metadata":{"execution":{"iopub.status.busy":"2024-06-30T16:31:51.027774Z","iopub.execute_input":"2024-06-30T16:31:51.028033Z","iopub.status.idle":"2024-06-30T18:32:03.935436Z","shell.execute_reply.started":"2024-06-30T16:31:51.028011Z","shell.execute_reply":"2024-06-30T18:32:03.934527Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86e3605e313843ed92bc2797476322b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 1:   0%|          | 0/8746 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch 1\nTraining loss: 0.8424105559132411\nValidation loss: 0.6738682794782762\nF1 Score (Weighted): 0.8112004897794232\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2:   0%|          | 0/8746 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch 2\nTraining loss: 0.571240645499295\nValidation loss: 0.7156030633565976\nF1 Score (Weighted): 0.84216169339436\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3:   0%|          | 0/8746 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch 3\nTraining loss: 0.4110366538661865\nValidation loss: 0.838454674407321\nF1 Score (Weighted): 0.8344256728717292\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4:   0%|          | 0/8746 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch 4\nTraining loss: 0.29352923692163796\nValidation loss: 0.7490406930984216\nF1 Score (Weighted): 0.8645572614873447\n","output_type":"stream"}],"execution_count":22}]}