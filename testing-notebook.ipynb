{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8826665,"sourceType":"datasetVersion","datasetId":5310562},{"sourceId":70954,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":59244,"modelId":81908}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import random\nfrom torch.utils.data import DataLoader, SequentialSampler\nimport torch\n\nfrom transformers import BertTokenizer\nfrom torch.utils.data import TensorDataset\n\nfrom transformers import BertForSequenceClassification\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T19:08:21.961325Z","iopub.execute_input":"2024-06-30T19:08:21.961914Z","iopub.status.idle":"2024-06-30T19:08:27.976158Z","shell.execute_reply.started":"2024-06-30T19:08:21.961862Z","shell.execute_reply":"2024-06-30T19:08:27.975152Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"We are using PyTorch as our deep learning framework. \nImporting necessary libraries to pre-processing, tokenizing and evaluation.","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport gensim\nfrom sklearn.metrics import f1_score, precision_score, recall_score\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T19:08:27.978087Z","iopub.execute_input":"2024-06-30T19:08:27.978824Z","iopub.status.idle":"2024-06-30T19:08:42.175252Z","shell.execute_reply.started":"2024-06-30T19:08:27.978788Z","shell.execute_reply":"2024-06-30T19:08:42.174406Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"Checking the device. We will proceed if there is a GPU available.","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n\nprint(device)\nif device.type == 'cuda':\n    print(torch.cuda.get_device_name(0))\n    print('Memory Usage:')\n    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3, 1), 'GB')\n    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3, 1), 'GB')\nelse:\n    exit(0)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T19:08:42.176422Z","iopub.execute_input":"2024-06-30T19:08:42.176921Z","iopub.status.idle":"2024-06-30T19:08:42.265417Z","shell.execute_reply.started":"2024-06-30T19:08:42.176892Z","shell.execute_reply":"2024-06-30T19:08:42.264506Z"},"trusted":true},"outputs":[{"name":"stdout","text":"cuda\nTesla T4\nMemory Usage:\nAllocated: 0.0 GB\nCached:    0.0 GB\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"Download the test set and load into a DataFrame.","metadata":{}},{"cell_type":"code","source":"#if not os.path.isfile(\"./Dataset/github-labels-top3-803k-test.csv\"):\n#    !curl \"https://tickettagger.blob.core.windows.net/datasets/github-labels-top3-803k-test.tar.gz\" | tar -xz \n#    #!mv github-labels-top3-803k-test.csv ./Dataset/\n\ntestdf = pd.read_csv(\"/kaggle/input/corona-nlp-test/Corona_NLP_test.csv\")\nprint(testdf.head())","metadata":{"execution":{"iopub.status.busy":"2024-06-30T19:08:42.266621Z","iopub.execute_input":"2024-06-30T19:08:42.267435Z","iopub.status.idle":"2024-06-30T19:08:42.327539Z","shell.execute_reply.started":"2024-06-30T19:08:42.267398Z","shell.execute_reply":"2024-06-30T19:08:42.326539Z"},"trusted":true},"outputs":[{"name":"stdout","text":"   UserName  ScreenName             Location     TweetAt  \\\n0         1       44953                  NYC  02-03-2020   \n1         2       44954          Seattle, WA  02-03-2020   \n2         3       44955                  NaN  02-03-2020   \n3         4       44956          Chicagoland  02-03-2020   \n4         5       44957  Melbourne, Victoria  03-03-2020   \n\n                                       OriginalTweet           Sentiment  \n0  TRENDING: New Yorkers encounter empty supermar...  Extremely Negative  \n1  When I couldn't find hand sanitizer at Fred Me...            Positive  \n2  Find out how you can protect yourself and love...  Extremely Positive  \n3  #Panic buying hits #NewYork City as anxious sh...            Negative  \n4  #toiletpaper #dunnypaper #coronavirus #coronav...             Neutral  \n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"Use the same label map used in the training.","metadata":{}},{"cell_type":"code","source":"label_dict = {'Neutral': 0, 'Positive': 1, 'Extremely Negative': 2, 'Negative': 3, 'Extremely Positive': 4}\ntestdf['label'] = testdf.Sentiment.replace(label_dict)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T19:08:42.330162Z","iopub.execute_input":"2024-06-30T19:08:42.330509Z","iopub.status.idle":"2024-06-30T19:08:42.342824Z","shell.execute_reply.started":"2024-06-30T19:08:42.330480Z","shell.execute_reply":"2024-06-30T19:08:42.341892Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/3114382342.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  testdf['label'] = testdf.Sentiment.replace(label_dict)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"Pre-preocessing function for removing whitespace and creating new feature.","metadata":{}},{"cell_type":"code","source":"def preprocess(row):\n    # concatenate title and body, then remove whitespaces\n    doc = \"\"\n    doc += str(row.TweetAt)\n    doc += \" \"\n    doc += str(row.OriginalTweet)\n    # https://radimrehurek.com/gensim/parsing/preprocessing.html\n    doc = gensim.parsing.preprocessing.strip_multiple_whitespaces(doc)\n    return doc","metadata":{"execution":{"iopub.status.busy":"2024-06-30T19:08:42.343945Z","iopub.execute_input":"2024-06-30T19:08:42.344278Z","iopub.status.idle":"2024-06-30T19:08:42.351990Z","shell.execute_reply.started":"2024-06-30T19:08:42.344253Z","shell.execute_reply":"2024-06-30T19:08:42.351145Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"Applying preporcessing step on the dataframe.","metadata":{}},{"cell_type":"code","source":"testdf['tweet_info'] = testdf.apply(preprocess, axis=1)\n\nnewTestDF = testdf[['Sentiment', 'OriginalTweet', 'label']]\ntestdf = newTestDF.copy()\nprint(testdf.head())","metadata":{"execution":{"iopub.status.busy":"2024-06-30T19:08:42.353102Z","iopub.execute_input":"2024-06-30T19:08:42.353838Z","iopub.status.idle":"2024-06-30T19:08:42.653958Z","shell.execute_reply.started":"2024-06-30T19:08:42.353803Z","shell.execute_reply":"2024-06-30T19:08:42.652920Z"},"trusted":true},"outputs":[{"name":"stdout","text":"            Sentiment                                      OriginalTweet  \\\n0  Extremely Negative  TRENDING: New Yorkers encounter empty supermar...   \n1            Positive  When I couldn't find hand sanitizer at Fred Me...   \n2  Extremely Positive  Find out how you can protect yourself and love...   \n3            Negative  #Panic buying hits #NewYork City as anxious sh...   \n4             Neutral  #toiletpaper #dunnypaper #coronavirus #coronav...   \n\n   label  \n0      2  \n1      1  \n2      4  \n3      3  \n4      0  \n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"Initiating tokenizer and encoding the test set.","metadata":{}},{"cell_type":"code","source":"\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased',\n                                          do_lower_case=True)\n\n\nencoded_data_test = tokenizer.batch_encode_plus(\n    testdf.OriginalTweet.values,\n    add_special_tokens=True,\n    return_attention_mask=True,\n    padding='longest',\n    truncation=True,\n    return_tensors='pt'\n)\n\ninput_ids_test = encoded_data_test['input_ids']\nattention_masks_test = encoded_data_test['attention_mask']\nlabels_test = torch.tensor(testdf.label.values)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T19:08:42.655493Z","iopub.execute_input":"2024-06-30T19:08:42.655799Z","iopub.status.idle":"2024-06-30T19:08:50.882271Z","shell.execute_reply.started":"2024-06-30T19:08:42.655773Z","shell.execute_reply":"2024-06-30T19:08:50.881380Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02f764b24d034cb1a6caad8b44f1d545"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec24b87dbbde4390a4113cd5b5de5830"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e78a58b5c0f04ed6b9d104e9f4916e97"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d09e3b2471104dab916660fb4a27e62a"}},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"Creating TensorDataset from encoded and masked test and creating a dataloader for testing.","metadata":{}},{"cell_type":"code","source":"dataset_test = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n\nbatch_size = 4\n\n\ndataloader_test = DataLoader(dataset_test,\n                             sampler=SequentialSampler(dataset_test),\n                             batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T19:08:50.883604Z","iopub.execute_input":"2024-06-30T19:08:50.883949Z","iopub.status.idle":"2024-06-30T19:08:50.891074Z","shell.execute_reply.started":"2024-06-30T19:08:50.883917Z","shell.execute_reply":"2024-06-30T19:08:50.889792Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"Declaring function for result generation.","metadata":{}},{"cell_type":"code","source":"\ndef result_generation(preds, labels):\n    label_dict_inverse = {v: k for k, v in label_dict.items()}\n\n    preds_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n\n    for label in np.unique(labels_flat):\n        y_preds = preds_flat[labels_flat == label]\n        y_true = labels_flat[labels_flat == label]\n        print(f'Class: {label_dict_inverse[label]}')\n        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n\n        P_c = precision_score(labels_flat, preds_flat, average=None, labels=[label])[0]\n        R_c = recall_score(labels_flat, preds_flat, average=None, labels=[label])[0]\n        F1_c = f1_score(labels_flat, preds_flat, average=None, labels=[label])[0]\n\n        print(f\"=*= {label_dict_inverse[label]} =*=\")\n        # print(\"Full precision:\\t\",P_c)\n        # print(\"Full recall:\\t\\t\",R_c)\n        # print(\"Full F1 score:\\t\",F1_c)\n        print(f\"precision:\\t{P_c:.4f}\")\n        print(f\"recall:\\t\\t{R_c:.4f}\")\n        print(f\"F1 score:\\t{F1_c:.4f}\")\n        print()\n\n    P = precision_score(labels_flat, preds_flat, average='micro')\n    R = recall_score(labels_flat, preds_flat, average='micro')\n    F1 = f1_score(labels_flat, preds_flat, average='micro')\n\n    print(\"=*= global =*=\")\n    print(f\"precision:\\t{P:.4f}\")\n    print(f\"recall:\\t\\t{R:.4f}\")\n    print(f\"F1 score:\\t{F1:.4f}\")\n    print()","metadata":{"execution":{"iopub.status.busy":"2024-06-30T19:08:50.892366Z","iopub.execute_input":"2024-06-30T19:08:50.892653Z","iopub.status.idle":"2024-06-30T19:08:50.919596Z","shell.execute_reply.started":"2024-06-30T19:08:50.892628Z","shell.execute_reply":"2024-06-30T19:08:50.918755Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"Fixing seed value for random sampling.","metadata":{}},{"cell_type":"code","source":"\nseed_val = 17\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T19:08:50.920746Z","iopub.execute_input":"2024-06-30T19:08:50.921137Z","iopub.status.idle":"2024-06-30T19:08:50.932227Z","shell.execute_reply.started":"2024-06-30T19:08:50.921102Z","shell.execute_reply":"2024-06-30T19:08:50.931368Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"Declaring the function for evaluating.","metadata":{}},{"cell_type":"code","source":"def evaluate(model, dataloader_val):\n    \n    model.eval()\n\n    loss_val_total = 0\n    predictions, true_vals = [], []\n\n    for batch in dataloader_val:\n\n        batch = tuple(b.to(device) for b in batch)\n\n        inputs = {'input_ids':      batch[0],\n                  'attention_mask': batch[1],\n                  'labels':         batch[2],\n                  }\n\n        with torch.no_grad():\n            outputs = model(**inputs)\n\n        loss = outputs[0]\n        logits = outputs[1]\n        loss_val_total += loss.item()\n\n        logits = logits.detach().cpu().numpy()\n        label_ids = inputs['labels'].cpu().numpy()\n        predictions.append(logits)\n        true_vals.append(label_ids)\n\n    loss_val_avg = loss_val_total/len(dataloader_val)\n\n    predictions = np.concatenate(predictions, axis=0)\n    true_vals = np.concatenate(true_vals, axis=0)\n\n    return loss_val_avg, predictions, true_vals\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T19:08:50.933269Z","iopub.execute_input":"2024-06-30T19:08:50.933563Z","iopub.status.idle":"2024-06-30T19:08:50.943946Z","shell.execute_reply.started":"2024-06-30T19:08:50.933538Z","shell.execute_reply":"2024-06-30T19:08:50.943077Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"Evaluating the model on different model states.","metadata":{}},{"cell_type":"code","source":"for i in range(1, 5):\n    print(\"Epoch: \", i)\n    model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n                                                          num_labels=len(\n                                                              label_dict),\n                                                          output_attentions=False,\n                                                          output_hidden_states=False)\n\n    model.to(device)\n    model.load_state_dict(torch.load(\n        '/kaggle/input/corona-nlp-test-model/pytorch/slug/1/model_colab.pth', map_location=device))\n\n    # %%\n    _, predictions, true_vals = evaluate(model, dataloader_test)\n\n    # %%\n    result_generation(predictions, true_vals)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T19:08:50.945070Z","iopub.execute_input":"2024-06-30T19:08:50.945401Z","iopub.status.idle":"2024-06-30T19:10:49.527700Z","shell.execute_reply.started":"2024-06-30T19:08:50.945355Z","shell.execute_reply":"2024-06-30T19:10:49.526623Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Epoch:  1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7206dbc5db94b2690c8a31c18c3557e"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Class: Neutral\nAccuracy: 534/619\n\n=*= Neutral =*=\nprecision:\t0.8725\nrecall:\t\t0.8627\nF1 score:\t0.8676\n\nClass: Positive\nAccuracy: 760/947\n\n=*= Positive =*=\nprecision:\t0.8342\nrecall:\t\t0.8025\nF1 score:\t0.8181\n\nClass: Extremely Negative\nAccuracy: 525/592\n\n=*= Extremely Negative =*=\nprecision:\t0.8294\nrecall:\t\t0.8868\nF1 score:\t0.8571\n\nClass: Negative\nAccuracy: 849/1041\n\n=*= Negative =*=\nprecision:\t0.8307\nrecall:\t\t0.8156\nF1 score:\t0.8231\n\nClass: Extremely Positive\nAccuracy: 528/599\n\n=*= Extremely Positive =*=\nprecision:\t0.8516\nrecall:\t\t0.8815\nF1 score:\t0.8663\n\n=*= global =*=\nprecision:\t0.8415\nrecall:\t\t0.8415\nF1 score:\t0.8415\n\nEpoch:  2\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Class: Neutral\nAccuracy: 534/619\n\n=*= Neutral =*=\nprecision:\t0.8725\nrecall:\t\t0.8627\nF1 score:\t0.8676\n\nClass: Positive\nAccuracy: 760/947\n\n=*= Positive =*=\nprecision:\t0.8342\nrecall:\t\t0.8025\nF1 score:\t0.8181\n\nClass: Extremely Negative\nAccuracy: 525/592\n\n=*= Extremely Negative =*=\nprecision:\t0.8294\nrecall:\t\t0.8868\nF1 score:\t0.8571\n\nClass: Negative\nAccuracy: 849/1041\n\n=*= Negative =*=\nprecision:\t0.8307\nrecall:\t\t0.8156\nF1 score:\t0.8231\n\nClass: Extremely Positive\nAccuracy: 528/599\n\n=*= Extremely Positive =*=\nprecision:\t0.8516\nrecall:\t\t0.8815\nF1 score:\t0.8663\n\n=*= global =*=\nprecision:\t0.8415\nrecall:\t\t0.8415\nF1 score:\t0.8415\n\nEpoch:  3\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Class: Neutral\nAccuracy: 534/619\n\n=*= Neutral =*=\nprecision:\t0.8725\nrecall:\t\t0.8627\nF1 score:\t0.8676\n\nClass: Positive\nAccuracy: 760/947\n\n=*= Positive =*=\nprecision:\t0.8342\nrecall:\t\t0.8025\nF1 score:\t0.8181\n\nClass: Extremely Negative\nAccuracy: 525/592\n\n=*= Extremely Negative =*=\nprecision:\t0.8294\nrecall:\t\t0.8868\nF1 score:\t0.8571\n\nClass: Negative\nAccuracy: 849/1041\n\n=*= Negative =*=\nprecision:\t0.8307\nrecall:\t\t0.8156\nF1 score:\t0.8231\n\nClass: Extremely Positive\nAccuracy: 528/599\n\n=*= Extremely Positive =*=\nprecision:\t0.8516\nrecall:\t\t0.8815\nF1 score:\t0.8663\n\n=*= global =*=\nprecision:\t0.8415\nrecall:\t\t0.8415\nF1 score:\t0.8415\n\nEpoch:  4\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Class: Neutral\nAccuracy: 534/619\n\n=*= Neutral =*=\nprecision:\t0.8725\nrecall:\t\t0.8627\nF1 score:\t0.8676\n\nClass: Positive\nAccuracy: 760/947\n\n=*= Positive =*=\nprecision:\t0.8342\nrecall:\t\t0.8025\nF1 score:\t0.8181\n\nClass: Extremely Negative\nAccuracy: 525/592\n\n=*= Extremely Negative =*=\nprecision:\t0.8294\nrecall:\t\t0.8868\nF1 score:\t0.8571\n\nClass: Negative\nAccuracy: 849/1041\n\n=*= Negative =*=\nprecision:\t0.8307\nrecall:\t\t0.8156\nF1 score:\t0.8231\n\nClass: Extremely Positive\nAccuracy: 528/599\n\n=*= Extremely Positive =*=\nprecision:\t0.8516\nrecall:\t\t0.8815\nF1 score:\t0.8663\n\n=*= global =*=\nprecision:\t0.8415\nrecall:\t\t0.8415\nF1 score:\t0.8415\n\n","output_type":"stream"}],"execution_count":13}]}